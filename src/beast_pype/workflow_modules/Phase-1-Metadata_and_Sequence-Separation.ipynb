{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f324b1-a8af-4f9b-a54e-1a0a39cbd051",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.011356,
     "end_time": "2025-02-03T21:34:24.539199",
     "exception": false,
     "start_time": "2025-02-03T21:34:24.527843",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Phase 1i: Seperating Metadata\n",
    "\n",
    "```\n",
    "Parameters\n",
    "-------------\n",
    "save_dir: str  \n",
    "    Path to directory for saving outputs in.\n",
    "\n",
    "cache_dir: str \n",
    "       Path to directory for cached objects in.\n",
    "\n",
    " metadata_db: str\n",
    "       Path to csv or tsv containing metadata.\n",
    "\n",
    "seperation_field: str\n",
    "        Field in metadata on which to seperate data and sequences. These seperated data set from an xml_set (all the data that goes into a BEAST 2 xml).\n",
    "\n",
    "root_strain_names: list of strs\n",
    "    IDs of sequences to be used as root.\n",
    "\n",
    "sample_id_field: str\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be format YYYY-MM-DD.\n",
    "\n",
    "data_filter: str\n",
    "    Optional can be an empy string, None or 'None'. Additional filter applieid to metadata_db when selecting \n",
    "    sequences and metadata to be used on pipeline. Must conform to [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html), see further [example](https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/). \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774ada4-db5b-4f49-b68f-f4e94ae36891",
   "metadata": {
    "papermill": {
     "duration": 0.018424,
     "end_time": "2025-02-03T21:34:24.567328",
     "exception": false,
     "start_time": "2025-02-03T21:34:24.548904",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "save_dir = 'runs_of_pipeline/2025-02-05'\n",
    "cache_dir = 'cache'\n",
    "metadata_db = None\n",
    "separation_field = 'country'\n",
    "sample_id_field = 'strain'\n",
    "collection_date_field = 'date'\n",
    "data_filter = None\n",
    "fasta_file = None"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import pakages",
   "id": "286459a1ab62be5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import json"
   ],
   "id": "d71eb4548c481868"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If pipeline_run_info.json exists open it. If not create empty dict.",
   "id": "b7cd0df191cac9da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if os.path.isfile(f'{save_dir}/pipeline_run_info.json'):\n",
    "    with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "        data = file.read()\n",
    "    file.close()\n",
    "    pipeline_run_info = json.loads(data)\n",
    "else:\n",
    "    pipeline_run_info = {}"
   ],
   "id": "35c5eeadfe49bd32"
  },
  {
   "cell_type": "markdown",
   "id": "b30946c3-dba1-4776-8eef-9b7067131fc2",
   "metadata": {
    "papermill": {
     "duration": 0.009004,
     "end_time": "2025-02-03T21:34:36.031360",
     "exception": false,
     "start_time": "2025-02-03T21:34:36.022356",
     "status": "completed"
    },
    "tags": []
   },
   "source": "## Load metadata and filter."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b0fa2-58f1-4eb8-864b-f42ff1c199ba",
   "metadata": {
    "papermill": {
     "duration": 0.186924,
     "end_time": "2025-02-03T21:34:36.227964",
     "exception": false,
     "start_time": "2025-02-03T21:34:36.041040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "if metadata_db.endswith('.tsv'):\n",
    "    delimiter = '\\t'\n",
    "elif metadata_db.endswith('.csv'):\n",
    "    delimiter = ','\n",
    "else:\n",
    "    raise TypeError(f\"metadata_db must be a csv or tsv file, ending with the apporpraite file extension. Value given is {metadata_db}\" )\n",
    "metadata_all_df = pd.read_csv(metadata_db,\n",
    "                               sep=delimiter,\n",
    "                               parse_dates=[collection_date_field]\n",
    "                               )\n",
    "\n",
    "if data_filter is not None:\n",
    "    metadata_all_df = metadata_all_df.query(data_filter)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load sequences:",
   "id": "58d30a22214a8a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sequences = SeqIO.parse(fasta_file, 'fasta')",
   "id": "34f88d861733036b"
  },
  {
   "cell_type": "markdown",
   "id": "72a9aead-d73d-442c-b38e-df4628370fbf",
   "metadata": {
    "papermill": {
     "duration": 0.009865,
     "end_time": "2025-02-03T21:34:36.267538",
     "exception": false,
     "start_time": "2025-02-03T21:34:36.257673",
     "status": "completed"
    },
    "tags": []
   },
   "source": "## Seperate metadata & Sequences"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708a5a8-b3fe-4a4c-80f5-1dbec032b8fc",
   "metadata": {
    "papermill": {
     "duration": 0.027332,
     "end_time": "2025-02-03T21:34:36.304398",
     "exception": false,
     "start_time": "2025-02-03T21:34:36.277066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xml_set_directories = {}\n",
    "xml_set_metadata = {}\n",
    "for xml_set in metadata_all_df[separation_field].unique():\n",
    "    xml_set_path = f'{save_dir}/{xml_set}'\n",
    "    os.makedirs(xml_set_path)\n",
    "    xml_set_directories[xml_set] = xml_set_path\n",
    "    xml_set_metadata = metadata_all_df[metadata_all_df[separation_field] == xml_set]\n",
    "    xml_set_metadata.to_csv(f'{xml_set_path}/metadata.csv', index=False)\n",
    "    ids = xml_set_metadata[sample_id_field]\n",
    "    selected_seqs = [seq_record for seq_record in sequences if seq_record.id in ids]\n",
    "    with open(f'{xml_set_path}/sequences.fasta', 'w') as handle:\n",
    "            SeqIO.write(selected_seqs, handle, 'fasta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948d747-badf-47b5-ad31-a2030691b431",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Saving information to pass onto the next Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361e9da-86fd-4696-8eaf-01748a19f7bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_run_info = {'xml set directories': xml_set_directories}\n",
    "\n",
    "with open(save_dir +'/pipeline_run_info.json', 'w') as fp:\n",
    "    json.dump(pipeline_run_info, fp, sort_keys=True, indent=4)\n",
    "\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "Phase-1-Data-Gathering.ipynb",
   "output_path": "Phase-1-Data-Gathering.ipynb",
   "parameters": {
    "cache_dir": "cache",
    "metadata_db": "/Drives/P/gisaid/merge/output/merge_ngdb-gisaid.tsv",
    "min_coverage": 0.925,
    "number_of_vois": 3,
    "root_strain_names": [
     "Wuhan/Hu-1/2019",
     "Wuhan/IPBCAMS-WH-01/2019"
    ],
    "save_dir": "runs_of_pipeline",
    "sequence_db": "/Drives/P/gisaid/nextclade/nextclade.fasta",
    "suggested_sample_sizes": [
     1000
    ]
   },
   "start_time": "2025-02-03T21:34:22.239444",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
