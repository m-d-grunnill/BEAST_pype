{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40e2efb-8a75-46fe-8270-9d1b4f943ccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Phase 5: Diagnosing Outputs and Generate Report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This notebook  attempts to do what the software [Tracer](https://beast.community/tracer) does and make some improvements. \n",
    "\n",
    "## Instructions\n",
    "\n",
    "Code cells of this Jupyter notebook should be run sequentially via shift+enter. Several cells will produce widgets that allow you to make various selections to select for MCMC chains that have convreged. Once you have made that selection left click on the cell below and press shift+enter.\n",
    "\n",
    "## Suggested Reading\n",
    "\n",
    "Up to and including \"**x% HPD interval**\" of:\n",
    "\n",
    "Drummond, Alexei J., and Bouckaert, Remco R. ‘Ch 10: Posterior Analysis and Post Processing.’ In Basian Evolutionary Analyses with BEAST. Cambridge University Press, 2015. https://www.cambridge.org/core/books/bayesian-evolutionary-analysis-with-beast/81F5894F05E87F13C688ADB00178EE00.\n",
    "\n",
    "The authors have been kind enough to make a draft copy of the book avialable at http://alexeidrummond.org/assets/publications/2015-drummond-bayesian.pdf.\n",
    "\n",
    "## Setup\n",
    "\n",
    "```\n",
    "Parameters\n",
    "-------------\n",
    "save_dir: str, oplional\n",
    "    Location of .log and .trees files from running several BEAST 2 MCMC chains using the same BEAST 2 xml.\n",
    "    If not prvided save_dir is assumed to be the location of this notebook.\n",
    "\n",
    "report_template: str\n",
    "    Path for report pemplate to use to generate report on the running of this workflow.\n",
    "\n",
    "metadata_path: str\n",
    "    Path of metadata pertaining to the fasta file used in generating  BEAST 2 xml.\n",
    "\n",
    "add_unreported_fields: bool, default True\n",
    "    If true the metadata of the notebook report_template will be searched for the entry \"BEAST outputs reported\".\n",
    "    Any parameter not listed but occuring in .log files will then be added to the notebook reporting on the outputs from\n",
    "    running this work workflow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24060b9ceeb193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:58:45.471658Z",
     "start_time": "2025-06-17T17:58:45.465950Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "report_template = None\n",
    "metadata_path = None\n",
    "add_unreported_fields = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d9d25-7b47-44b9-8b6e-70ca2dd08e15",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b06f0-6f66-432f-9e45-2c7ed13a08a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T18:23:56.580243Z",
     "start_time": "2025-06-17T18:23:56.575975Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "import papermill as pm\n",
    "from beast_pype.mcmc_diagnostics import BEASTDiag\n",
    "from beast_pype.report_gen import add_unreported_outputs\n",
    "from beast_pype.workflow import get_slurm_job_stats\n",
    "import warnings\n",
    "import os\n",
    "import importlib.resources as importlib_resources\n",
    "# stop annoying matplotlib warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fb01c-10e0-433a-ba78-9c23652a0f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T18:25:41.728640Z",
     "start_time": "2025-06-17T18:25:41.723222Z"
    }
   },
   "outputs": [],
   "source": [
    "if report_template is None:\n",
    "    report_template =  importlib_resources.path('beast_pype', 'report_templates') / 'BDSKY-Report.ipynb'\n",
    "\n",
    "if save_dir is None:\n",
    "    save_dir=os.getcwd()\n",
    "\n",
    "if metadata_path is None:\n",
    "    raise ValueError('metadata_path is required.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e9ae3610f5d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:48:27.227100Z",
     "start_time": "2025-06-13T20:48:27.221595Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "pipeline_run_info[\"Chains Used\"] = []\n",
    "pipeline_run_info[\"Burn-In\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a6ce9-03f2-453c-a757-8d0f28ba8fbe",
   "metadata": {},
   "source": [
    "## Get Intormation on Run of Pipeline\n",
    "### Slurm Job Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c0d1d-c5e4-4fe4-80f1-a919aa91db77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:48:51.025517Z",
     "start_time": "2025-02-10T19:48:51.018372Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    slurm_job_stats = get_slurm_job_stats(pipeline_run_info['slurm job IDs'])\n",
    "    slurm_job_stats.to_csv(f\"{save_dir}/slurm_job_stats.csv\", index=False)\n",
    "    to_display = slurm_job_stats.\n",
    "except:\n",
    "    job_ids_request = ','.join([f\"{entry}.batch\" for entry in pipeline_run_info['slurm job IDs']])\n",
    "    request = f\"sacct --jobs={job_ids_request} --format=JobID,AllocTres,Elapsed,CPUTime,TotalCPU,MaxRSS -p --delimiter='/t'\"\n",
    "    to_display = ('The function for summarising slurm job statistics into a table may not work properly with certain slurm configurations (formating issues). \\n' +\n",
    "                    'We suggest you attempt the following from the command line on the terminal in which you ran this beast_pype workflow:\\n' +\n",
    "                  request)\n",
    "\n",
    "display(to_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7b776-43a5-4e7d-a788-ed0c4067883a",
   "metadata": {},
   "source": [
    "## Load log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db9ec44868c670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:48:32.010273Z",
     "start_time": "2025-06-13T20:48:31.947322Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_diag = BEASTDiag(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e13084-7042-4d9b-8040-545317732ba8",
   "metadata": {},
   "source": [
    "## Selecting burnin and Chains to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc038373782759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:48:35.521034Z",
     "start_time": "2025-06-13T20:48:34.271565Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_diag_widget = sample_diag.generate_widget()\n",
    "sample_diag_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f3c07d0cd215c",
   "metadata": {},
   "source": [
    "## Merge Kept chains\n",
    "\n",
    "### Log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158606c-028d-4d14-8764-6b3d0a2dcf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:50:35.830599Z",
     "start_time": "2025-06-13T20:50:34.512268Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -l -s {sample_diag.logcombiner_args(suffix='.log')}\n",
    "source activate beast_pype\n",
    "\n",
    "logcombiner -b $1 -log ${@:3}  -o $2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c737e77630bcdd4",
   "metadata": {},
   "source": [
    "### Tree Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8e137b7d61174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:50:44.248569Z",
     "start_time": "2025-06-13T20:50:41.855644Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash -l -s {sample_diag.logcombiner_args(suffix='.trees')}\n",
    "source activate beast_pype\n",
    "\n",
    "logcombiner -b $1 -log ${@:3}  -o $2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254a8610b233044",
   "metadata": {},
   "source": [
    "### Recoard Chains used & burnin for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04f94511affbf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:50:54.637919Z",
     "start_time": "2025-06-13T20:50:54.634834Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_run_info[\"Chains Used\"].append(deepcopy(sample_diag.selected_chains))\n",
    "pipeline_run_info[\"Burn-In\"].append(deepcopy(sample_diag.burinin_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20d87196d2b7b",
   "metadata": {},
   "source": [
    "## Update the pipeline_run_info json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e76dc6fa8304f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:51:36.226001Z",
     "start_time": "2025-06-13T20:51:35.892777Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{save_dir}/pipeline_run_info.json', 'w') as fp:\n",
    "    json.dump(pipeline_run_info, fp, sort_keys=True, indent=4)\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3685a24873403e",
   "metadata": {},
   "source": [
    "## Generate output Report\n",
    "Now you can now move on to visualising outputs from BEAST using a report template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d9d69-5a14-453f-baba-ccf4c908e612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_params = {'save_dir': save_dir, 'metadata_path': metadata_path}\n",
    "output_report_path = f'{save_dir}/BEASTPype-Report.ipynb'\n",
    "if add_unreported_fields:\n",
    "    add_unreported_outputs(report_template, f'{sample_diag.directory}/merged.log', output_report_path)\n",
    "output = pm.execute_notebook(input_path=output_report_path,\n",
    "                             output_path=output_report_path,\n",
    "                             parameters=report_params,\n",
    "                             progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd7afe5052ad1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Convert Output Report from Jupyter Notebook to Notebook\n",
    "\n",
    "This also removes code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda79e1407d65444",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -l -s {output_report_path}\n",
    "source activate beast_pype\n",
    "jupyter nbconvert --to html --no-input $@"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
