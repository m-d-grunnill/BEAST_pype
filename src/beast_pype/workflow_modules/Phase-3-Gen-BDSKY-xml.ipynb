{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d95f35b078330d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Phase 3: Setting up the BEAST xmls\n",
    "\n",
    "```\n",
    "Parameters\n",
    "-------------\n",
    "save_dir: str  \n",
    "    Path to directory for saving outputs in.\n",
    "\n",
    "cache_dir: str \n",
    "    Path to directory for cached objects in.\n",
    "\n",
    "template_xml_path: str\n",
    "    Path to template BEAST xml.\n",
    "\n",
    "use_initial_tree:  bool, default True\n",
    "    Is there an inital tree to be used. If not the initial tree will not be used in generating a BEAST 2 xml\n",
    "    and will BEAST 2 generate its own.\n",
    "\n",
    "rt_dimensions: int, default=None\n",
    "    Number of Rt dimensions (time periods).\n",
    "\n",
    "rt_changes: dict: dict of strings {'unit': 'days, weeks or years', 'every': int/float, 'end': 'oldest tip'}, optional\n",
    "    Instructions for setting rt_change date, going backwards from youngest sample in fasta_file.\n",
    "    rt_changes[\"end\"] currently only supports \"oldest tip\".\n",
    "    If given rt_dimensions must equal None.\n",
    "\n",
    "metadata_path: str\n",
    "       Path to csv or tsv containing metadata.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be format YYYY-MM-DD.\n",
    "\n",
    "initial_tree_path: str\n",
    "    Path to initial_tree. Should .nwk file.\n",
    "\n",
    "fasta_path: str\n",
    "    Path to fasta file containing sequences.\n",
    "\n",
    "origin_start_addition float\n",
    "    This + initial temporal tree height is used as starting value of origin.\n",
    "    We recommend using an estimate of infection period for the pathogen being studied. **Value should be in years.**\n",
    "    Origin prio will be unform:\n",
    "        Lower value: time in years from oldest to youngest sequence in fasta_file\n",
    "        Start value: origin_start_addition + initial temporal tree height\n",
    "        Upper value:  initial temporal tree height + origin_upper_addition.\n",
    "\n",
    "origin_upper_addition: float/int\n",
    "    This + initial temporal tree height is used as upper value of origin prior. **Value should be in years.**\n",
    "    Origin prio will be unform:\n",
    "        Lower value: time in years from oldest to youngest sequence in fasta_file\n",
    "        Start value: origin_start_addition + initial temporal tree height\n",
    "        Upper value:  initial temporal tree height + origin_upper_addition.\n",
    "\n",
    "origin_prior: dict {'lower': float, 'upper': float, 'start': float}, optional\n",
    "       Details of the origin prior. assumed to be uniformly distributed.\n",
    "\n",
    "log_file_basename: str, optional\n",
    "    If provided .tree, .log and .state files from running BEAST 2 will have this name prefixed by 'run-{number}-',\n",
    "    number being that of the chain.\n",
    "\n",
    "chain_length: int\n",
    "    Number of chains to use for BEAST runs.\n",
    "\n",
    "trace_log_every: int\n",
    "    How often to save a log file during BEAST runs.\n",
    "\n",
    "tree_log_every: int\n",
    "    How often to save a tree file during BEAST runs.\n",
    "\n",
    "screen_log_every: int\n",
    "    How often to output to screen during BEAST runs.\n",
    "\n",
    "store_state_every: int \n",
    "    How often to store MCMC state during BEAST runs.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f2dc8b3083270",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "save_dir = 'runs_of_pipeline/2025-02-05'\n",
    "template_xml_path = 'template_beast_xmls/BDSKY_serial_COVID-19_template.xml'\n",
    "fasta_file = None\n",
    "use_initial_tree = True\n",
    "initial_tree_path = None\n",
    "metadata_path = None\n",
    "rt_dimensions = None\n",
    "rt_changes = None\n",
    "collection_date_field = 'date'\n",
    "origin_upper_addition = None\n",
    "origin_prior = None\n",
    "origin_start_addition = 10/365.25\n",
    "log_file_basename=None\n",
    "chain_length = int(1e7)\n",
    "trace_log_every = int(1e4)\n",
    "tree_log_every = int(1e4)\n",
    "screen_log_every = int(1e4)\n",
    "store_state_every = int(1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1385ce75f60021",
   "metadata": {},
   "source": [
    "Import packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60f708f20b547d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from beast_pype.beast_xml_gen import gen_bdsky_serial_xml\n",
    "from beast_pype.date_utilities import date_to_decimal\n",
    "from copy import deepcopy\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4a71e-009d-4676-b9c6-531cfe3bf327",
   "metadata": {},
   "source": [
    "### Search for files in save_dir if not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671208bb-a52f-4156-a2e5-0d9dc604562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    if initial_tree_path is None:\n",
    "        initial_tree_path = f'{save_dir}/down_sampled_time.nwk'\n",
    "        if not os.path.exists(initial_tree_path):\n",
    "            initial_tree_path = f'{save_dir}/full_time.nwk'\n",
    "            if not os.path.exists(initial_tree_path):\n",
    "                initial_tree_path = f'{save_dir}/iqtree.treefile'\n",
    "                if not os.path.exists(initial_tree_path):\n",
    "                    raise FileNotFoundError(f'Initial tree file not found. initial_tree_path has not been provided and none of the files down_sampled_time.nwk, full_time.nwk or iqtree.treefile can not be found in save_dir ({save_dir}).')\n",
    "\n",
    "if metadata_path is None:\n",
    "    metadata_path = f'{save_dir}/metadata.csv'\n",
    "    if not os.path.exists(metadata_path):\n",
    "        raise FileNotFoundError(f'Metadata file not found. metadata_path has not been provided and the file metadata.csv can not be found in save_dir ({save_dir}).')\n",
    "\n",
    "if fasta_file is None:\n",
    "    fasta_file = f'{save_dir}/sequences.fasta_file'\n",
    "    if not os.path.exists(fasta_file):\n",
    "        raise FileNotFoundError(f'Fasta file not found. fasta_file has not been provided and the file sequences.fasta_file can not be found in save_dir ({save_dir}).')\n",
    "\n",
    "\n",
    "if not use_initial_tree and initial_tree_path is not None:\n",
    "    raise AssertionError('use_initial_tree is False but you have provided an initial_tree_path?')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b8b11-ecdc-4616-a8ce-6ac38b1f82ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## IQtree fix\n",
    "\n",
    "IQ tree is offended by the charachters: '/'. The code below corrects this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58cbf9-a800-4f81-9ccf-1d8072bafb6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    correction_dict = {seq_record.id.replace('/', '_'): seq_record.id\n",
    "                       for seq_record in SeqIO.parse(fasta_file, \"fasta\")}\n",
    "    tree_file = initial_tree_path\n",
    "    fh = open(tree_file)\n",
    "    tree = fh.read()\n",
    "    for changed, original in correction_dict.items():\n",
    "        tree = tree.replace(changed, original)\n",
    "\n",
    "    oh = open(tree_file, 'w')\n",
    "    oh.write(tree)\n",
    "    oh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0e874-3ea9-405c-bddf-51b420ba86f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generate the $R_t$ change dates.  \n",
    "\n",
    "Back every 4 weeks from the youngest tip. For VOIs stop at the youngest tip out of the oldest tips for each sample. For DR back an extra 4 weeks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9e147-a3b9-4d9c-84b8-42db408fe250",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rt_changes in ['', 'None']:\n",
    "    rt_changes = None\n",
    "\n",
    "if rt_changes is not None:\n",
    "    metadata = pd.read_csv(metadata_path, parse_dates=[collection_date_field])\n",
    "    youngest_tip = metadata[collection_date_field].max()\n",
    "    if rt_changes['end'] == 'oldest tip':\n",
    "        end = metadata[collection_date_field].min()\n",
    "    else:\n",
    "        raise ValueError('rt_changes[\"end\"] currently only supports \"oldest tip\".')\n",
    "    rt_change_dates = []\n",
    "    offsets = {rt_changes['unit']: rt_changes['every']}\n",
    "    date_to_append = deepcopy(youngest_tip)\n",
    "    while date_to_append > end:\n",
    "        date_to_append = date_to_append - DateOffset(**offsets)\n",
    "        rt_change_dates.append(date_to_append)\n",
    "else:\n",
    "    rt_change_dates = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e915d8-82c3-4382-8b09-bd6e9b7f071e",
   "metadata": {},
   "source": [
    "## Actually Generating the BEAST2 xmls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1520ffbfb66f1c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    gen_bdsky_serial_xml(\n",
    "       template_path=template_xml_path,\n",
    "       sequences_path=fasta_file,\n",
    "       metadata_path=metadata_path,\n",
    "       initial_tree_path=initial_tree_path,\n",
    "       origin_prior=origin_prior,\n",
    "       origin_upper_height_addition=origin_upper_addition,\n",
    "       origin_start_addition=origin_start_addition,\n",
    "       output_path=f\"{save_dir}/beast.xml\",\n",
    "       rt_dimensions=rt_dimensions,\n",
    "       rt_change_dates=rt_change_dates,\n",
    "       log_file_basename=log_file_basename,\n",
    "       chain_length=chain_length,\n",
    "       trace_log_every=trace_log_every,\n",
    "       tree_log_every=tree_log_every,\n",
    "       screen_log_every=screen_log_every,\n",
    "       store_state_every=store_state_every\n",
    "    )\n",
    "else:\n",
    "    gen_bdsky_serial_xml(template_path=template_xml_path,\n",
    "                 sequences_path=fasta_file,\n",
    "                 metadata_path=metadata_path,\n",
    "                 output_path=f\"{save_dir}/beast.xml\",\n",
    "                 origin_prior=origin_prior,\n",
    "                 rt_dimensions=rt_dimensions,\n",
    "                 rt_change_dates=rt_change_dates,\n",
    "                 log_file_basename=log_file_basename,\n",
    "                 chain_length=chain_length,\n",
    "                 trace_log_every=trace_log_every,\n",
    "                 tree_log_every=tree_log_every,\n",
    "                 screen_log_every=screen_log_every,\n",
    "                 store_state_every=store_state_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de5303-cf5b-4078-b58c-997116c661dc",
   "metadata": {},
   "source": [
    "### Add Information to pipeline_run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cc3a1-4b41-4e1c-8398-8f0cd2da65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "if metadata_path.endswith('.tsv'):\n",
    "    delimiter = '\\t'\n",
    "elif metadata_path.endswith('.csv'):\n",
    "    delimiter = ','\n",
    "else:\n",
    "    raise TypeError(\n",
    "        f\"metadata_path must be a csv or tsv file, ending with the appropriate file extension. Value given is {metadata_path}\")\n",
    "metadata= pd.read_csv(metadata_path, parse_dates=[collection_date_field], sep=delimiter)\n",
    "youngest_tip = metadata[collection_date_field].max()\n",
    "youngest_tip = date_to_decimal(youngest_tip)\n",
    "pipeline_run_info = {'youngest tip': youngest_tip}\n",
    "if rt_change_dates is not None:\n",
    "    pipeline_run_info['Rt change dates'] =[str(value.date()) for value in rt_change_dates]\n",
    "if rt_dimensions is not None:\n",
    "    pipeline_run_info['Rt dimensions'] = rt_dimensions\n",
    "with open(save_dir +'/pipeline_run_info.json', 'w') as fp:\n",
    "    json.dump(pipeline_run_info, fp, sort_keys=True, indent=4)\n",
    "\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
