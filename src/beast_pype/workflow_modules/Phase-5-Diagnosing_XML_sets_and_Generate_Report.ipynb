{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40e2efb-8a75-46fe-8270-9d1b4f943ccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Phase 5: Diagnosing Outputs from Running XML-sets and Generate Report\n",
    "\n",
    "This notebook  attempts to do what the software [Tracer](https://beast.community/tracer) does and make some improvements. \n",
    "\n",
    "## Instructions\n",
    "\n",
    "Code cells of this Jupyter notebook should be run sequentially via shift+enter. Several cells will produce widgets that allow you to make various selections to select for MCMC chains that have convreged. Once you have made that selection left click on the cell below and press shift+enter.\n",
    "\n",
    "## Suggested Reading\n",
    "\n",
    "Up to and including \"**x% HPD interval**\" of:\n",
    "\n",
    "Drummond, Alexei J., and Bouckaert, Remco R. ‘Ch 10: Posterior Analysis and Post Processing.’ In Basian Evolutionary Analyses with BEAST. Cambridge University Press, 2015. https://www.cambridge.org/core/books/bayesian-evolutionary-analysis-with-beast/81F5894F05E87F13C688ADB00178EE00.\n",
    "\n",
    "The authors have been kind enough to make a draft copy of the book avialable at http://alexeidrummond.org/assets/publications/2015-drummond-bayesian.pdf.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24060b9ceeb193",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:58:45.471658Z",
     "start_time": "2025-06-17T17:58:45.465950Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "report_template = None\n",
    "add_unreported_fields = True\n",
    "collection_date_field = \"date\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d9d25-7b47-44b9-8b6e-70ca2dd08e15",
   "metadata": {},
   "source": [
    "Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b06f0-6f66-432f-9e45-2c7ed13a08a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T18:23:56.580243Z",
     "start_time": "2025-06-17T18:23:56.575975Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "import papermill as pm\n",
    "from beast_pype.mcmc_diagnostics import BEASTDiag\n",
    "from beast_pype.report_gen import add_unreported_outputs\n",
    "from beast_pype.workflow import get_slurm_job_stats\n",
    "import warnings\n",
    "import os\n",
    "import importlib.resources as importlib_resources\n",
    "# stop annoying matplotlib warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fb01c-10e0-433a-ba78-9c23652a0f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T18:25:41.728640Z",
     "start_time": "2025-06-17T18:25:41.723222Z"
    }
   },
   "outputs": [],
   "source": [
    "if report_template is None:\n",
    "    report_template =  importlib_resources.path('beast_pype', 'report_templates') / 'BDSKY-Report.ipynb'\n",
    "\n",
    "if save_dir is None:\n",
    "    save_dir=os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e9ae3610f5d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:48:27.227100Z",
     "start_time": "2025-06-13T20:48:27.221595Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "pipeline_run_info[\"Chains Used\"] = {}\n",
    "pipeline_run_info[\"Burn-In\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a6ce9-03f2-453c-a757-8d0f28ba8fbe",
   "metadata": {},
   "source": [
    "## Get Intormation on Run of Pipeline\n",
    "### Slurm Job Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c0d1d-c5e4-4fe4-80f1-a919aa91db77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:48:51.025517Z",
     "start_time": "2025-02-10T19:48:51.018372Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "BEASTDiags after this cell."
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    slurm_job_stats = get_slurm_job_stats(pipeline_run_info['slurm job IDs'])\n",
    "    slurm_job_stats.to_csv(f\"{save_dir}/slurm_job_stats.csv\", index=False)\n",
    "    to_display = slurm_job_stats\n",
    "except:\n",
    "    job_ids_request = ','.join([f\"{entry}.batch\" for entry in pipeline_run_info['slurm job IDs']])\n",
    "    request = f\"sacct --jobs={job_ids_request} --format=JobID,AllocTres,Elapsed,CPUTime,TotalCPU,MaxRSS -p --delimiter='/t'\"\n",
    "    to_display = ('The function for summarising slurm job statistics into a table may not work properly with certain slurm configurations (formating issues). \\n' +\n",
    "                    'We suggest you attempt the following from the command line on the terminal in which you ran this beast_pype workflow:\\n' +\n",
    "                  request)\n",
    "\n",
    "display(to_display)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_beast_pype",
   "language": "python",
   "name": "dev_beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
