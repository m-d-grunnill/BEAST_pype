{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee348d7-8a73-4f0e-95ec-1418ebfa2161",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.014814,
     "end_time": "2025-06-19T17:55:08.764643",
     "exception": false,
     "start_time": "2025-06-19T17:55:08.749829",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Workflow BDSKY-serial Strain Surveillance Notebook\n",
    "\n",
    "\n",
    "This Workflow Notebook is for Comaring different lineages/varients of a pathogen agianst each other.\n",
    "\n",
    "\n",
    "```\n",
    "Parameters\n",
    "-------------\n",
    "overall_save_dir: str\n",
    "    Path to where you are saving all the runs of this pipeline.\n",
    "\n",
    "specific_run_save_dir: str, optional\n",
    "    Subdirecotry of overall_save_dir you wish to save the outputs from this pipeline iine. \n",
    "    If None, 'None' or an emply string a timestamp of format 'YYYY-MM-DD_hour-min-sec' is used instead.\n",
    "\n",
    "cache_dir: str \n",
    "       Name to use for cache directory. Saved within overall_save_dir/specific_run_save_dir bet deleted the end of this workflow notebook.\n",
    "\n",
    " metadata_db: str\n",
    "       Path to csv or tsv containing metadata.\n",
    "\n",
    "seperation_field: str\n",
    "        Field in metadata on which to seperate data and sequences. These seperated data set from an xml_set (all the data that goes into a BEAST 2 xml).\n",
    "\n",
    "root_strain_names: list of strs\n",
    "    IDs of sequences to be used as root.\n",
    "\n",
    "sample_id_field: str\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be format YYYY-MM-DD.\n",
    "\n",
    "lineage_field: str\n",
    "    Name of field in metadata_db containing lineage sequences belong to.\n",
    "\n",
    "metadata_dtypes: str\n",
    "    Optional can be an empy string, None or 'None'. Path to json defining pandas data types for metadata_db.\n",
    "\n",
    "data_filter: str\n",
    "    Optional can be an empy string, None or 'None'. Additional filter applieid to metadata_db when selecting \n",
    "    sequences and metadata to be used on pipeline. Must conform to [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html), see further [example](https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/).\n",
    "\n",
    "sequence_db: str\n",
    "    Path to fasta file containing sequences.\n",
    "\n",
    "partition: str\n",
    "    Name of partition to use when calling `sbatch`.\n",
    "\n",
    "down_sample_to: int\n",
    "    If the number sequences in a fasta file is above this the number of sequences is cut to this number via downsampling.\n",
    "\n",
    "origin_start_addition: float\n",
    "    Suggested infection period of pathogen. **Should be in years.** This + initial MLE tree height is used as starting value of origin.\n",
    "\n",
    "origin_upper_addition: float/int\n",
    "    This + initial MLE tree height is used as upper value of origin prior.\n",
    "\n",
    "sample_id_field: str\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be format YYYY-MM-DD.\n",
    "\n",
    "template_xml_path:\n",
    "    Path to template BEAST xml.\n",
    "\n",
    "chain_length: int\n",
    "    Number of chains to use for BEAST runs.\n",
    "\n",
    "trace_log_every: int\n",
    "    How often to save a log file during BEAST runs.\n",
    "\n",
    "tree_log_every: int\n",
    "    How often to save a tree file during BEAST runs.\n",
    "\n",
    "screen_log_every: int\n",
    "    How often to output to screen during BEAST runs.\n",
    "\n",
    "store_state_every: int \n",
    "    How often to store MCMC state during BEAST runs.\n",
    "\n",
    "number_of_chains: int\n",
    "    Number of chains to use (repeated runs to do) when running BEAST.\n",
    "\n",
    "seeds: list of ints\n",
    "    Seeds to use when running BEAST.\n",
    "\n",
    "partition: str\n",
    "    Name of partition to use when calling `sbatch`.\n",
    "\n",
    "beast_ram: str\n",
    "    RAM to use for each run of beast see sbatch documentation.\n",
    "\n",
    "beast_threads: int\n",
    "    Threads/CPUs to use for each run of beast see https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "burnin_percentage: int\n",
    "    Perecentage burnin to use.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0d4d772d4084a",
   "metadata": {
    "papermill": {
     "duration": 0.025038,
     "end_time": "2025-06-19T17:55:08.801879",
     "exception": false,
     "start_time": "2025-06-19T17:55:08.776841",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Needed in this notebook\n",
    "overall_save_dir = '../test_runs_of_pipeline'\n",
    "specific_run_save_dir=None\n",
    "\n",
    "\n",
    "# Needed in Phases 1 & 3\n",
    "sample_id_field = 'strain'\n",
    "collection_date_field = 'date'\n",
    "\n",
    "# Needed in Phases 2 & 5\n",
    "partition=None\n",
    "\n",
    "# Used in Phase 1:\n",
    "metadata_db = None\n",
    "separation_field = 'country'\n",
    "data_filter = None\n",
    "root_strain_names = None\n",
    "metadata_dtypes = None\n",
    "\n",
    "# Used in Phase 2:\n",
    "sequence_db = None\n",
    "\n",
    "# Used in Phase 3:\n",
    "down_sample_to = None\n",
    "\n",
    "\n",
    "# Used in Phase 4:\n",
    "template_xml_path = '../template_beast_xmls/BDSKY_serial_COVID-19_template.xml'\n",
    "origin_upper_addition = 2\n",
    "origin_start_addition = 10/365.25\n",
    "chain_length = int(5e5)\n",
    "trace_log_every = int(5e2)\n",
    "tree_log_every = int(5e2)\n",
    "screen_log_every = int(5e2)\n",
    "store_state_every = int(5e2)\n",
    "\n",
    "# Used in Phase 5:\n",
    "number_of_chains = 4\n",
    "seeds = None\n",
    "beast_ram = \"32G\"\n",
    "beast_threads=6\n",
    "\n",
    "# Used in Phase 6:\n",
    "burnin_percentage = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fb2a4-ae8c-42db-a96f-e73675bd415a",
   "metadata": {
    "papermill": {
     "duration": 0.011494,
     "end_time": "2025-06-19T17:55:08.858576",
     "exception": false,
     "start_time": "2025-06-19T17:55:08.847082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import packages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea894b39-974f-4d5c-9796-d46aece0680d",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.350249,
     "end_time": "2025-06-19T17:55:09.220317",
     "exception": true,
     "start_time": "2025-06-19T17:55:08.870068",
     "status": "failed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from beast_pype.workflow import check_file_for_phrase\n",
    "from beast_pype.mcmc_diagnostics import gen_xml_set_diag_notebook\n",
    "from papermill.parameterize import parameterize_notebook\n",
    "from papermill.iorw import load_notebook_node, write_ipynb\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import papermill as pm\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "from numpy.random import randint \n",
    "import shutil\n",
    "import importlib.resources as importlib_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a9be5-25c6-43e4-8a43-e677a2ee19f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Creating Folders and Subfolders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d4f34-9b4b-432b-b471-0f15b2803dab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(overall_save_dir):\n",
    "    os.makedirs(overall_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720f264-a51c-4f55-b671-f7cdf227a4af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Create a folder of today's date to save into within save_dir and reassign save_dir to that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b12632-5558-45f4-aaca-1431d410491d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if specific_run_save_dir is None or specific_run_save_dir in ['', 'None']:\n",
    "    now = datetime.now()\n",
    "    specific_run_save_dir = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "save_dir = overall_save_dir +'/'+ specific_run_save_dir\n",
    "cache_dir = save_dir +'/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9f69d-4b8d-4e22-8d52-7332a2f40e1c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "If save_dir and and cache_dir do not exist create them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce13003-64e0-4801-9d22-b9eba1fa7d19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in [save_dir, cache_dir]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f0009-0b93-499d-8246-79db0307412b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Placing Common Parameters in a Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d82b3e47f4a2a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    'save_dir' : save_dir,\n",
    "    'cache_dir' : cache_dir\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9197b63a1b94b12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Creating a record for runtimes\n",
    "\n",
    "This record list of dirtionaries will be turned into a pandas dataframe and saved as a csv at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb3f93570c1555",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5145cd0fbb811c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Set path to workflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ed8424eef2dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow_modules = importlib_resources.path('beast_pype', 'workflow_modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53522c5b-0019-420f-84e7-21bb4b127043",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 1: Data Gathering\n",
    "\n",
    "### Placing Phase 1 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15750-675b-4779-9713-b4a17401bce7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_1_start= perf_counter()\n",
    "phase_1_params = {\n",
    "    **common_params,\n",
    "    **{val_name: eval(val_name) for val_name in ['metadata_db', 'data_filter', 'sample_id_field', 'collection_date_field', 'fasta_file']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e63d53e8d5d3b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 1i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff146bcc64eb6dde",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=Phase-1-Metadata_and_Sequence-Separation.ipynb\n",
    "phase_1i_log =pm.execute_notebook(input_path=f'{workflow_modules}/Phase-1-Metadata_and_Sequence-Separation.ipynb',\n",
    "                                 output_path=save_dir + '/Phase-1-Metadata_and_Sequence-Separation.ipynb',\n",
    "                                 parameters=phase_1_params,\n",
    "                                 progress_bar=True,\n",
    "                                 nest_asyncio=True\n",
    "                                )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-1-Metadata_and_Sequence-Separation.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_1_start\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bfd2db9a24c7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 2: Data Pre-Processing\n",
    "### Phase 2i: Building an IQ Tree tree.\n",
    "#### Placing Phase 2i Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280655f2bf2c404",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_2i_start = perf_counter()\n",
    "phase_2i_params = {**common_params,\n",
    "                   'fasta_file': 'sequences.fasta',\n",
    "                  'partition': partition\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd05080e75054",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a642b40d0607a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=Phase-2i-IQTree.ipynb\n",
    "\n",
    "phase_2i_log = pm.execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree.ipynb',\n",
    "                                  output_path=save_dir + '/Phase-2i-IQTree.ipynb',\n",
    "                                  parameters=phase_2i_params,\n",
    "                                  progress_bar=True,\n",
    "                                  nest_asyncio=True\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c5c6860dfd17d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Wait for IQtrees to be Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893da97ce505869",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(save_dir + '/pipeline_run_info.json', 'r') as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "xml_set_directories = pipeline_run_info[\"xml set directories\"]\n",
    "for directory in xml_set_directories.values():\n",
    "    out_file = directory + '/iqtree.out'\n",
    "    check_file_for_phrase(out_file)\n",
    "\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-2i-IQTree.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_2i_start\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cc904-6b7c-46fa-8d62-952fa81b5c82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Phase 2ii: TreeTime & Down Sampling\n",
    "\n",
    "#### Placing Phase 2ii Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1231e6-7d1d-4af1-b98d-4c18e31cb3c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_2ii_start = perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff97d05-e5ff-42e5-a019-e5e2fa336fd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb8145-17a7-4047-b89d-b95b272b67c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=Phase-2ii-TreeTime-and-Down-Sampling.ipynb\n",
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "xml_set_directories = pipeline_run_info['xml set directories']\n",
    "for sub_dir in xml_set_directories.values(): # This loop could and should be parallellisd\n",
    "    phase_2ii_params = {\n",
    "        'save_dir': sub_dir,      \n",
    "        **{val_name: eval(val_name) for val_name in ['sample_id_field', 'collection_date_field', 'down_sample_to']}\n",
    "        }\n",
    "    phase_2ii_log = pm.execute_notebook(input_path=f'{workflow_modules}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                      output_path=f'{sub_dir}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                      parameters=phase_2ii_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True\n",
    "                                     )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_2ii_start\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f672959e2da4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 3 Generating BEAST xmls\n",
    "\n",
    "### Running Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675157d6d474176d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_3_start = perf_counter()\n",
    "for sub_dir in xml_set_directories.values(): # This loop could and should be parallellisd\n",
    "    phase_3_params = {\n",
    "        'save_dir': sub_dir,\n",
    "        **{val_name: eval(val_name) for val_name in [\n",
    "            'template_xml_path',\n",
    "            'use_initial_tree',\n",
    "            'initial_tree_path',\n",
    "            'rt_dimensions',\n",
    "            'collection_date_field',\n",
    "            'origin_start_addition',\n",
    "            'origin_upper_addition',\n",
    "            'log_file_basename',\n",
    "            'origin_prior',\n",
    "            'chain_length',\n",
    "            'trace_log_every',\n",
    "            'tree_log_every',\n",
    "            'screen_log_every',\n",
    "            'store_state_every']}\n",
    "        }\n",
    "    phase_3_log = pm.execute_notebook(input_path=f'{workflow_modules}/Phase-3-Gen-BDSKY-xml.ipynb',\n",
    "                                      output_path=f'{sub_dir}/Phase-3-Gen-BDSKY-xml.ipynb',\n",
    "                                      parameters=phase_3_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True\n",
    "                                     )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-3-Gen-BDSKY-xml.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_3_start\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c940e-a5fa-454f-a652-128f4ad19d6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 4 Running BEAST\n",
    "\n",
    "BEASTs random number seed can select the same seed for multiple runs if they are launched close together in time (such as proromatically). Therefore lets use numpy to generate our seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ea52e-c776-461c-86b0-241587cd8e85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if seeds is None:\n",
    "    number_of_seeds=number_of_chains*(len(xml_set_directories))\n",
    "    seeds = randint(low=1, high=int(1e6), size=number_of_seeds).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25a3dc-cbb6-42ad-8329-dc005b373933",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Record seeds in pipeline_run_info json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86526e0-af8d-4a8b-9a7e-617ac61ab7e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "pipeline_run_info['seeds'] = seeds\n",
    "with open(save_dir +'/pipeline_run_info.json', 'w') as fp:\n",
    "    json.dump(pipeline_run_info, fp, sort_keys=True, indent=4)\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290cf00e-ef20-4afc-9198-8bb853efe062",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Placing Phase 4 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da6b4c2c2215d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_4_params = {**common_params,\n",
    "                  'number_of_chains': number_of_chains,\n",
    "                  'seeds':seeds,\n",
    "                  'partition': partition,\n",
    "                  'beast_threads':beast_threads,\n",
    "                  'beast_ram':beast_ram}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7d043c49bfebc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Running Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3298a0779f93b1a",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=Phase5-Running-BEAST.ipynb\n",
    "phase_4_log = pm.execute_notebook(input_path=f'{workflow_modules}/Phase-4-Running-BEAST.ipynb',\n",
    "                                  output_path=save_dir + '/Phase-4-Running-BEAST.ipynb',\n",
    "                                  parameters=phase_4_params,\n",
    "                                  progress_bar=True,\n",
    "                                  nest_asyncio=True\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1311d-1db0-4a74-8cf2-b63da4ee5f48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Add Slurm Job IDs and Names to pipeline_run_info.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ea63e-5938-44d8-9505-06253738716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir + \"/pipeline_run_info.json\", \"r\") as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = json.loads(data)\n",
    "with open(cache_dir +'/slurm_job_ids.txt', 'r') as fp:\n",
    "    entries = fp.read().splitlines() \n",
    "fp.close()\n",
    "pipeline_run_info['slurm job IDs'] = entries\n",
    "with open(save_dir +'/pipeline_run_info.json', 'w') as fp:\n",
    "    json.dump(pipeline_run_info, fp, sort_keys=True, indent=4)\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f089750-b059-4a5f-9e70-d896d75034ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 5: Diagnosing Outputs and Generate Report\n",
    "\n",
    "Curently this has to be performed manually. That being said, the code cell below will parameterize a copy of the notebook ready to run. See below for location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46c12e-6246-4589-9a05-10cd6900b793",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_xml_set_diag_notebook(save_dir, directories_to_exclude = [cache_dir])\n",
    "phase_5_params = {'save_dir': None,\n",
    "                  'report_template': str(importlib_resources.path('beast_pype', 'report_templates') / 'COVID-Surveillance-Report.ipynb'),\n",
    "                  'add_unreported_fields': False,\n",
    "                  'collection_date_field':collection_date_field\n",
    "                 } \n",
    "phase_5_notebook = load_notebook_node(f'{save_dir}/Phase-5-Diagnosing_XML_sets_and_Generate_Report.ipynb')\n",
    "phase_5_notebook = parameterize_notebook(phase_5_notebook, phase_5_params)\n",
    "write_ipynb(phase_5_notebook, f'{save_dir}/Phase-5-Diagnosing_XML_sets_and_Generate_Report.ipynb')\n",
    "print(f'Phase 5 notebook is ready for manual use at: \\n{save_dir}/Phase-5-Diagnosing_XML_sets_and_Generate_Report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494b9dd-bfbb-4fa3-bc4f-bf565fbf87d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Recording Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516d160-5840-443f-b236-174514d988fd",
   "metadata": {},
   "source": [
    "Converting to pandas DataFrame and saving as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c093c-1960-4adb-b1b3-c3175be05761",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame.from_records(runtime_records)\n",
    "runtime_df.to_csv(save_dir + \"/runtimes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3fe31-89b9-4df4-bc80-0ea9ec6dfca8",
   "metadata": {},
   "source": [
    "### Delete Cache direcory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d05bbfb-cf3f-4478-96da-768c4ed21e13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(cache_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.588428,
   "end_time": "2025-06-19T17:55:09.651794",
   "environment_variables": {},
   "exception": true,
   "input_path": "workflows/Workflow-BDSKY-Strain-Survailance.ipynb",
   "output_path": "runs_of_pipeline_Test/2025-06-19_12-54-54/Workflow-BDSKY-Strain-Survailance.ipynb",
   "parameters": {
    "beast_ram": "32G",
    "beast_threads": 6,
    "burnin_percentage": 10,
    "chain_length": 500000,
    "collection_date_field": "date",
    "data_filter": "country == \"Canada\" and coverage >= 0.925",
    "dr_strain": "LP.8.1.1",
    "infection_period": 0.02737850787132101,
    "lineage_field": "pango_lineage",
    "metadata_db": "/Drives/P/gisaid/merge/output/beast_pype_test_data_2025-06-19.tsv",
    "metadata_dtypes": "metadata_dtypes/nml_covid.json",
    "number_of_chains": 4,
    "origin_upper_addition": 2,
    "overall_save_dir": "runs_of_pipeline_Test",
    "partition": "NMLResearch",
    "root_strain_names": [
     "Wuhan/Hu-1/2019",
     "Wuhan/IPBCAMS-WH-01/2019"
    ],
    "sample_id_field": "strain",
    "screen_log_every": 500,
    "sequence_db": "/Drives/P/gisaid/nextclade/beast_pype_test_data_2025-06-19.fasta",
    "specific_run_save_dir": "2025-06-19_12-54-54",
    "store_state_every": 500,
    "sub_vars_dict": {
     "KP.3.3.5": [
      "KP.3.3.5",
      "PG.1",
      "PG.2",
      "PG.3",
      "PG.4",
      "PG.4.1",
      "PG.5",
      "PG.6"
     ],
     "LP.8.1.1": [
      "LP.8.1.1",
      "NY.1",
      "NY.2",
      "NY.4",
      "NY.4.1",
      "NY.5",
      "NY.6",
      "NY.7",
      "NY.7.1",
      "NY.7.1.1",
      "NY.7.2",
      "NY.8",
      "NY.9",
      "NY.10",
      "NY.11",
      "NY.11.1",
      "NY.12",
      "NY.12.1",
      "NY.13",
      "NY.14",
      "NY.15",
      "NY.16",
      "NY.16.1",
      "NY.16.2",
      "NY.17",
      "NY.17.1",
      "NY.17.2",
      "NY.18",
      "NY.18.1"
     ],
     "NY.3": [
      "NY.3",
      "NY.3.1",
      "NY.3.1.1",
      "NY.3.2"
     ],
     "XFG": [
      "XFG",
      "XFG.1",
      "XFG.2",
      "XFG.3",
      "XFG.3.1",
      "XFG.4",
      "XFG.5",
      "XFG.6",
      "XFG.7"
     ]
    },
    "suggested_sample_sizes": [
     200
    ],
    "template_xml_path": "template_beast_xmls/BDSKY_serial_COVID-19_template.xml",
    "trace_log_every": 500,
    "tree_log_every": 500,
    "voi_strains": [
     "XFG",
     "NY.3",
     "KP.3.3.5"
    ]
   },
   "start_time": "2025-06-19T17:55:02.063366",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
